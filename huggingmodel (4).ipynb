{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3ff30d-2e4b-4a46-b837-86c013eb4796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.34.1 in /opt/app-root/lib/python3.9/site-packages (4.34.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (4.66.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (2023.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (1.24.4)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (3.13.1)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.34.1) (0.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.34.1) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.34.1) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.34.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.34.1) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: mlflow in /opt/app-root/lib/python3.9/site-packages (2.8.1)\n",
      "Requirement already satisfied: torchvision in /opt/app-root/lib/python3.9/site-packages (0.16.1)\n",
      "Requirement already satisfied: einops in /opt/app-root/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (3.20.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (6.8.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (1.2.2)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (6.1.3)\n",
      "Requirement already satisfied: gunicorn<22 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (21.2.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (0.4.4)\n",
      "Requirement already satisfied: pyarrow<15,>=4.0.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (14.0.1)\n",
      "Requirement already satisfied: pytz<2024 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (2023.3)\n",
      "Requirement already satisfied: scipy<2 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (1.10.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (6.0.1)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (3.1.32)\n",
      "Requirement already satisfied: packaging<24 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (23.1)\n",
      "Requirement already satisfied: querystring-parser<2 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (2.0.23)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (8.1.6)\n",
      "Requirement already satisfied: Flask<4 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: numpy<2 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (2.31.0)\n",
      "Requirement already satisfied: cloudpickle<3 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (2.2.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (3.5.1)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: entrypoints<1 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: pandas<3 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (1.5.3)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (0.18.0)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (3.6.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/app-root/lib/python3.9/site-packages (from mlflow) (1.12.1)\n",
      "Requirement already satisfied: torch==2.1.1 in /opt/app-root/lib/python3.9/site-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/app-root/lib/python3.9/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (1.12)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (3.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/app-root/lib/python3.9/site-packages (from torch==2.1.1->torchvision) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1->torchvision) (12.3.101)\n",
      "Requirement already satisfied: Mako in /opt/app-root/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /opt/app-root/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /opt/app-root/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.8.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/app-root/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/app-root/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in /opt/app-root/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.16)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/app-root/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.6.1)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/app-root/lib/python3.9/site-packages (from Flask<4->mlflow) (1.7.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/app-root/lib/python3.9/site-packages (from Flask<4->mlflow) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/app-root/lib/python3.9/site-packages (from Flask<4->mlflow) (2.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/app-root/lib/python3.9/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.16.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.42.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/app-root/lib/python3.9/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/app-root/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch==2.1.1->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.34.1\n",
    "!pip install mlflow torchvision einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc87a57-1d5c-4aef-a7ac-3509406b9308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://mlflow-server.mlflow.svc.cluster.local:8080\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import mlflow\n",
    "import os\n",
    "import logging\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "MLFLOW_ROUTE = os.getenv(\"MLFLOW_ROUTE\")\n",
    "print(MLFLOW_ROUTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65785cc-edb3-4364-b2d0-2dfb8cf7ecdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/3', creation_time=1700576882759, experiment_id='3', last_update_time=1700576882759, lifecycle_stage='active', name='yi34b', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_ROUTE)\n",
    "mlflow.set_experiment(\"yi34b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e12dd-b695-4bbd-82bb-9bb6447cd033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bd7384f7484993b0e9c28bf65f91d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380b3ef9b02842129bb1d983bc0eb2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00007.safetensors:   0%|          | 0.00/9.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4546648b7e5a4e88aa54c897dc23a2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00007.safetensors:   0%|          | 0.00/9.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dd48323df9495889fbee34afa9fd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00007.safetensors:   0%|          | 0.00/9.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7c5bb0f85640d0815cf0488308c800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00007.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e52730c86148d8b2134509b3343d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00007.safetensors:   0%|          | 0.00/9.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"01-ai/Yi-34B\", trust_remote_code=True)\n",
    "\n",
    "chat_pipeline = transformers.pipeline(model=\"01-ai/Yi-34B\", trust_remote_code=True, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8ed9c-da51-4b63-a0a6-f1d134f240f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "  model_info = mlflow.transformers.log_model(\n",
    "    transformers_model=chat_pipeline,\n",
    "    artifact_path=\"yi34bmodel\",\n",
    "    input_example=\"hi there\"\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48478c9-37c3-45be-bac4-9f587fd68998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b3b6ee56a3417497ce1b510b4b46d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/22 00:43:43 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "The following failures occurred while downloading one or more artifacts from http://mlflow-server.mlflow.svc.cluster.local:8080/api/2.0/mlflow-artifacts/artifacts/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts:\n##### File phi15model/model/pytorch_model-00004-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00005-of-00012.bin #####\n('Connection broken: IncompleteRead(1058 bytes read, 50 more expected)', IncompleteRead(1058 bytes read, 50 more expected))\n##### File phi15model/model/pytorch_model-00010-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00007-of-00012.bin #####\n('Connection broken: IncompleteRead(227 bytes read, 757 more expected)', IncompleteRead(227 bytes read, 757 more expected))\n##### File phi15model/model/pytorch_model-00001-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00002-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00011-of-00012.bin #####\n('Connection broken: IncompleteRead(214 bytes read, 330 more expected)', IncompleteRead(214 bytes read, 330 more expected))\n##### File phi15model/model/pytorch_model-00003-of-00012.bin #####\n('Connection broken: IncompleteRead(271 bytes read, 1613 more expected)', IncompleteRead(271 bytes read, 1613 more expected))\n##### File phi15model/model/pytorch_model-00009-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load as interactive pyfunc\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlflow-artifacts:/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts/phi15model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#make predictions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#chatbot.predict(\"What is the best way to get to Antarctica?\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m chatbot\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich kubernetes should should I use? Red Hat or VMWare?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/mlflow/pyfunc/__init__.py:652\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[1;32m    619\u001b[0m     model_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    620\u001b[0m     suppress_warnings: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    621\u001b[0m     dst_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    622\u001b[0m     model_config: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    623\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyFuncModel:\n\u001b[1;32m    624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    Load a model stored in Python function format.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;124;03m                                             release without warning.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[1;32m    655\u001b[0m         _warn_dependency_requirement_mismatches(local_path)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/mlflow/tracking/artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m                    a local output path will be created.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/mlflow/store/artifact/artifact_repo.py:221\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    217\u001b[0m     template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##### File \u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[38;5;124m #####\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{error}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    219\u001b[0m         template\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mpath, error\u001b[38;5;241m=\u001b[39merror) \u001b[38;5;28;01mfor\u001b[39;00m path, error \u001b[38;5;129;01min\u001b[39;00m failed_downloads\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    220\u001b[0m     )\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    222\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following failures occurred while downloading one or more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m artifacts from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_truncate_error(failures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst_path, artifact_path)\n",
      "\u001b[0;31mMlflowException\u001b[0m: The following failures occurred while downloading one or more artifacts from http://mlflow-server.mlflow.svc.cluster.local:8080/api/2.0/mlflow-artifacts/artifacts/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts:\n##### File phi15model/model/pytorch_model-00004-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00005-of-00012.bin #####\n('Connection broken: IncompleteRead(1058 bytes read, 50 more expected)', IncompleteRead(1058 bytes read, 50 more expected))\n##### File phi15model/model/pytorch_model-00010-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00007-of-00012.bin #####\n('Connection broken: IncompleteRead(227 bytes read, 757 more expected)', IncompleteRead(227 bytes read, 757 more expected))\n##### File phi15model/model/pytorch_model-00001-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00002-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n##### File phi15model/model/pytorch_model-00011-of-00012.bin #####\n('Connection broken: IncompleteRead(214 bytes read, 330 more expected)', IncompleteRead(214 bytes read, 330 more expected))\n##### File phi15model/model/pytorch_model-00003-of-00012.bin #####\n('Connection broken: IncompleteRead(271 bytes read, 1613 more expected)', IncompleteRead(271 bytes read, 1613 more expected))\n##### File phi15model/model/pytorch_model-00009-of-00012.bin #####\n(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))"
     ]
    }
   ],
   "source": [
    "# Load as interactive pyfunc\n",
    "\n",
    "chatbot = mlflow.pyfunc.load_model(\"mlflow-artifacts:/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts/phi15model\")\n",
    "#make predictions\n",
    "#chatbot.predict(\"What is the best way to get to Antarctica?\")\n",
    "\n",
    "chatbot.predict(\"Which kubernetes should should I use? Red Hat or VMWare?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41d32c7b-b712-4cfe-9c2e-741b7cb728cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1944a53c552d4078889ed65c1b9a9ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/21 14:19:39 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "The following failures occurred while downloading one or more artifacts from http://mlflow-server.mlflow.svc.cluster.local:8080/api/2.0/mlflow-artifacts/artifacts/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts:\n##### File phi15model/model/pytorch_model-00007-of-00012.bin #####\n('Connection broken: IncompleteRead(0 bytes read, 5 more expected)', IncompleteRead(0 bytes read, 5 more expected))\n##### File phi15model/model/pytorch_model-00004-of-00012.bin #####\n('Connection broken: IncompleteRead(712 bytes read, 892 more expected)', IncompleteRead(712 bytes read, 892 more expected))\n##### File phi15model/model/pytorch_model-00003-of-00012.bin #####\n('Connection broken: IncompleteRead(698 bytes read, 1278 more expected)', IncompleteRead(698 bytes read, 1278 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlflow-artifacts:/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts/phi15model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mservepath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/mlflow/artifacts/__init__.py:60\u001b[0m, in \u001b[0;36mdownload_artifacts\u001b[0;34m(artifact_uri, run_id, artifact_path, dst_path, tracking_uri)\u001b[0m\n\u001b[1;32m     57\u001b[0m     pathlib\u001b[38;5;241m.\u001b[39mPath(dst_path)\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artifact_uri \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m artifact_path \u001b[38;5;241m=\u001b[39m artifact_path \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m store \u001b[38;5;241m=\u001b[39m _get_store(store_uri\u001b[38;5;241m=\u001b[39mtracking_uri)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/mlflow/tracking/artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m                    a local output path will be created.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/mlflow/store/artifact/artifact_repo.py:221\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    217\u001b[0m     template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##### File \u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[38;5;124m #####\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{error}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    219\u001b[0m         template\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mpath, error\u001b[38;5;241m=\u001b[39merror) \u001b[38;5;28;01mfor\u001b[39;00m path, error \u001b[38;5;129;01min\u001b[39;00m failed_downloads\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    220\u001b[0m     )\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    222\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following failures occurred while downloading one or more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m artifacts from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_truncate_error(failures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst_path, artifact_path)\n",
      "\u001b[0;31mMlflowException\u001b[0m: The following failures occurred while downloading one or more artifacts from http://mlflow-server.mlflow.svc.cluster.local:8080/api/2.0/mlflow-artifacts/artifacts/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts:\n##### File phi15model/model/pytorch_model-00007-of-00012.bin #####\n('Connection broken: IncompleteRead(0 bytes read, 5 more expected)', IncompleteRead(0 bytes read, 5 more expected))\n##### File phi15model/model/pytorch_model-00004-of-00012.bin #####\n('Connection broken: IncompleteRead(712 bytes read, 892 more expected)', IncompleteRead(712 bytes read, 892 more expected))\n##### File phi15model/model/pytorch_model-00003-of-00012.bin #####\n('Connection broken: IncompleteRead(698 bytes read, 1278 more expected)', IncompleteRead(698 bytes read, 1278 more expected))"
     ]
    }
   ],
   "source": [
    "mlflow.artifacts.download_artifacts(artifact_uri=\"mlflow-artifacts:/2/5bbf49af4e714aeb9b6be13f9c9ee53c/artifacts/phi15model\" ,dst_path='servepath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae40ff2-a6fb-4d45-95de-a1f51cfdf853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71656ea5413e45b3b94affd7ef9e89b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: D\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./servepath/chatbot/components/tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./servepath/chatbot/model\")\n",
    "\n",
    "# Let's chat for 5 lines\n",
    "for step in range(1):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dcf219c-aaea-4055-ae5d-8ed6d4fbde3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#torch.set_default_device(\"cuda\")\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/phi-1_5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/phi-1_5\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m```python\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mdef print_prime(n):\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m   \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m   Print all primes between 1 and n\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m   \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'''\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/transformers/models/auto/auto_factory.py:560\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    564\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/transformers/modeling_utils.py:3085\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3082\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map)\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 3085\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;66;03m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[1;32m   3088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-1_5/5fd430c7bcd28140560faee2014d1228338e19a0/modeling_phi.py:942\u001b[0m, in \u001b[0;36mPhiForCausalLM.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: PhiConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m \u001b[43mPhiModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m CausalLMHead(config)\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m CausalLMLoss()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-1_5/5fd430c7bcd28140560faee2014d1228338e19a0/modeling_phi.py:904\u001b[0m, in \u001b[0;36mPhiModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: PhiConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 904\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membd \u001b[38;5;241m=\u001b[39m \u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([ParallelBlock(config, block_idx\u001b[38;5;241m=\u001b[39mi) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mn_layer)])\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-1_5/5fd430c7bcd28140560faee2014d1228338e19a0/modeling_phi.py:73\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: PretrainedConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwte \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_embd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39membd_pdrop)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/torch/nn/modules/sparse.py:142\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq \u001b[38;5;241m=\u001b[39m scale_grad_by_freq\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    143\u001b[0m                             requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze)\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_parameters()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#torch.set_default_device(\"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n",
    "inputs = tokenizer('''```python\n",
    "def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4928e5d-1033-4e48-9990-5851693c4c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
